{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path=\"data/train\"\n",
    "test_data_path=\"data/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 28\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "image_size = 80\n",
    "labels = os.listdir(train_data_path)\n",
    "print(\"number of classes:\",len(labels))\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(f'{train_data_path}',i)\n",
    "    for j in os.listdir(folderPath):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        h,w=img.shape[:2]\n",
    "        if h>image_size or w>image_size:\n",
    "            img = cv2.resize(img,(image_size, image_size))\n",
    "        else:\n",
    "            scale_factor = min(image_size/h, image_size/w)\n",
    "            # Calculate the new image size\n",
    "            new_height = int(h * scale_factor)\n",
    "            new_width = int(w * scale_factor)\n",
    "\n",
    "            # Calculate the amount of padding\n",
    "            pad_height = image_size - new_height\n",
    "            pad_width = image_size - new_width\n",
    "\n",
    "            # Calculate the amount of padding on each side\n",
    "            top = pad_height // 2\n",
    "            bottom = pad_height - top\n",
    "            left = pad_width // 2\n",
    "            right = pad_width - left\n",
    "\n",
    "            # Add padding to the image\n",
    "            img_padded = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "            # Resize the image to the desired output size\n",
    "            img_resized = cv2.resize(img_padded, (image_size,image_size))\n",
    "            img=img_resized\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdata_len=len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights calculation for weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={}\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(f'{train_data_path}',i)\n",
    "    class_weights[labels.index(i)]=trdata_len/len(os.listdir(folderPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#Checking the availability of GPU\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3386, 80, 80, 3) (3386,)\n"
     ]
    }
   ],
   "source": [
    "#Shuffling data points\n",
    "from sklearn.utils import shuffle\n",
    "X_train,y_train=shuffle(X_train,y_train,random_state=101)\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical labels to one hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train = y_train_new\n",
    "y_train = tf.keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    vertical_flip=True,\n",
    "    rescale=1/255.,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=batch_size,subset='training')\n",
    "valid_generator=datagen.flow(X_train, y_train, batch_size=batch_size,subset='validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = []\n",
    "y_final_test = []\n",
    "for i in labels:\n",
    "    folderPath = os.path.join(f'{test_data_path}',i)\n",
    "    for j in os.listdir(folderPath):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        h,w=img.shape[:2]\n",
    "        if h>image_size or w>image_size:\n",
    "            img = cv2.resize(img,(image_size, image_size))\n",
    "        else:\n",
    "            scale_factor = min(image_size/h, image_size/w)\n",
    "            # Calculate the new image size\n",
    "            new_height = int(h * scale_factor)\n",
    "            new_width = int(w * scale_factor)\n",
    "\n",
    "            # Calculate the amount of padding\n",
    "            pad_height = image_size - new_height\n",
    "            pad_width = image_size - new_width\n",
    "\n",
    "            # Calculate the amount of padding on each side\n",
    "            top = pad_height // 2\n",
    "            bottom = pad_height - top\n",
    "            left = pad_width // 2\n",
    "            right = pad_width - left\n",
    "\n",
    "            # Add padding to the image\n",
    "            img_padded = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "            # Resize the image to the desired output size\n",
    "            img_resized = cv2.resize(img_padded, (image_size,image_size))\n",
    "            img=img_resized\n",
    "        X_final_test.append(img)\n",
    "        y_final_test.append(i)\n",
    "        \n",
    "X_final_test = np.array(X_final_test)\n",
    "y_final_test = np.array(y_final_test)\n",
    "\n",
    "y_final_test_new = []\n",
    "for i in y_final_test:\n",
    "    y_final_test_new.append(labels.index(i))\n",
    "y_final_test = y_final_test_new\n",
    "y_final_test = tf.keras.utils.to_categorical(y_final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test=X_final_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 80, 80, 3) (361, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_final_test.shape,y_final_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Sequential()\n",
    "Model.add(Conv2D(32,(3,3),activation=\"relu\", input_shape=(80,80,3)))\n",
    "Model.add(MaxPooling2D((2,2)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Conv2D(64,(3,3),  activation=\"relu\",padding=\"same\"))\n",
    "Model.add(MaxPooling2D((2,2)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Conv2D(128,(3,3), activation=\"relu\",padding=\"same\"))\n",
    "Model.add(MaxPooling2D((2,2)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Conv2D(256,(3,3), activation=\"relu\",padding=\"same\"))\n",
    "Model.add(MaxPooling2D((2,2)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Conv2D(512,(3,3), activation=\"relu\",padding=\"same\"))\n",
    "Model.add(MaxPooling2D((2,2)))\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(128,activation=\"relu\"))\n",
    "Model.add(Dense(64,activation=\"sigmoid\"))\n",
    "Model.add(Dense(28,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_56 (Conv2D)          (None, 78, 78, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 39, 39, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 39, 39, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 39, 39, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 19, 19, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 19, 19, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 9, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 9, 9, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 9, 9, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 2, 2, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,842,844\n",
      "Trainable params: 1,841,884\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3) ,metrics='accuracy')\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 22:02:00.930592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/85 [===========================>..] - ETA: 0s - loss: 0.1125 - accuracy: 0.2077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 22:02:04.716638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 17ms/step - loss: 0.1115 - accuracy: 0.2189 - val_loss: 3.2714 - val_accuracy: 0.0945\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0754 - accuracy: 0.5382 - val_loss: 2.7569 - val_accuracy: 0.2555\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0462 - accuracy: 0.7626 - val_loss: 2.3516 - val_accuracy: 0.3663\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0281 - accuracy: 0.8439 - val_loss: 2.0220 - val_accuracy: 0.4668\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0173 - accuracy: 0.9088 - val_loss: 0.9510 - val_accuracy: 0.8021\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0120 - accuracy: 0.9324 - val_loss: 0.6997 - val_accuracy: 0.8375\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0092 - accuracy: 0.9446 - val_loss: 0.5955 - val_accuracy: 0.8641\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0062 - accuracy: 0.9653 - val_loss: 0.4778 - val_accuracy: 0.8936\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 0.0046 - accuracy: 0.9719 - val_loss: 0.3997 - val_accuracy: 0.9129\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 0.0032 - accuracy: 0.9790 - val_loss: 0.3325 - val_accuracy: 0.9202\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0024 - accuracy: 0.9834 - val_loss: 0.3018 - val_accuracy: 0.9247\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0021 - accuracy: 0.9838 - val_loss: 0.2878 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0016 - accuracy: 0.9897 - val_loss: 0.2827 - val_accuracy: 0.9365\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0012 - accuracy: 0.9915 - val_loss: 0.2360 - val_accuracy: 0.9394\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 9.9402e-04 - accuracy: 0.9930 - val_loss: 0.2323 - val_accuracy: 0.9424\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 8.5954e-04 - accuracy: 0.9926 - val_loss: 0.2163 - val_accuracy: 0.9498\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 7.3999e-04 - accuracy: 0.9952 - val_loss: 0.2118 - val_accuracy: 0.9527\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 7.5131e-04 - accuracy: 0.9948 - val_loss: 0.2481 - val_accuracy: 0.9321\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 6.0900e-04 - accuracy: 0.9956 - val_loss: 0.2097 - val_accuracy: 0.9468\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 5.7535e-04 - accuracy: 0.9970 - val_loss: 0.2269 - val_accuracy: 0.9439\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 4.4845e-04 - accuracy: 0.9985 - val_loss: 0.2236 - val_accuracy: 0.9424\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 3.9108e-04 - accuracy: 0.9996 - val_loss: 0.1972 - val_accuracy: 0.9468\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 3.5126e-04 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9527\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 3.1308e-04 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9527\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.8804e-04 - accuracy: 0.9996 - val_loss: 0.2033 - val_accuracy: 0.9439\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.5528e-04 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9527\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 2.3519e-04 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9439\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.1692e-04 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9572\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.9948e-04 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9483\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.8748e-04 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9483\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.7960e-04 - accuracy: 0.9996 - val_loss: 0.1974 - val_accuracy: 0.9542\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.6355e-04 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9513\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.5247e-04 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9542\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.4306e-04 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9513\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.3199e-04 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9498\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.2315e-04 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9513\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.1544e-04 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9542\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.0798e-04 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9498\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.0188e-04 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9542\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 9.6308e-05 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9513\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 9.0796e-05 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9527\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 8.5723e-05 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9542\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 8.0755e-05 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9586\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 7.6555e-05 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9586\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 7.2167e-05 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9557\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 6.8245e-05 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9527\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 6.4490e-05 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9513\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 6.0881e-05 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9572\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 5.7566e-05 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9527\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 5.4841e-05 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9542\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 5.1816e-05 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9527\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 4.9241e-05 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9527\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 4.6850e-05 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9513\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 4.4364e-05 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9542\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 4.2447e-05 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9542\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 4.0255e-05 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9527\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 3.8369e-05 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9498\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 3.6473e-05 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9527\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 3.4766e-05 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9527\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 3.3168e-05 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9513\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 3.1647e-05 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9557\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 3.0043e-05 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9513\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 2.8751e-05 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9527\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.7378e-05 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9527\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.6146e-05 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9498\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.4968e-05 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9513\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 2.3817e-05 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9527\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.2728e-05 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9498\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 2.1691e-05 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9513\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 2.0765e-05 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9527\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.9753e-05 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9542\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.8901e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9513\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.8042e-05 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9557\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.7251e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9586\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.6491e-05 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9498\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.5746e-05 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9498\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.5104e-05 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9572\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.4446e-05 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9527\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 1.3803e-05 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9468\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.3208e-05 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9527\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.2611e-05 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9542\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.2090e-05 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9527\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.1598e-05 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9513\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.1074e-05 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9542\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.0597e-05 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9498\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 1.0140e-05 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9483\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 9.7375e-06 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9557\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 9.3330e-06 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9527\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 8.9236e-06 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9542\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 8.5331e-06 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9483\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 8.1812e-06 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9513\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 7.8442e-06 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9527\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 7.5088e-06 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9483\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 7.1928e-06 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9498\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 6.8975e-06 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9498\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 6.6145e-06 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9542\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 6.3280e-06 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9542\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 6.0742e-06 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9527\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 5.8146e-06 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9483\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 5.5843e-06 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9513\n"
     ]
    }
   ],
   "source": [
    "history = Model.fit(train_generator, epochs=100,validation_data=valid_generator,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Test accuracy: 0.9390581846237183\n"
     ]
    }
   ],
   "source": [
    "score_cnn = Model.evaluate(X_final_test,y_final_test, verbose = 0)\n",
    "\n",
    "print('final Test accuracy:', score_cnn[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning using Resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model=tf.keras.applications.ResNet152V2(include_top=False,weights=\"imagenet\",input_tensor=None,input_shape=(80,80,3))\n",
    "\n",
    "for l in resnet_model.layers:\n",
    "# Freezing the model\n",
    "  l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "TModel = Sequential()\n",
    "TModel.add(Input(shape=(80,80,3)))\n",
    "TModel.add(resnet_model)\n",
    "TModel.add(Flatten())\n",
    "TModel.add(BatchNormalization())\n",
    "TModel.add(Dense(5000,activation=\"relu\"))\n",
    "TModel.add(BatchNormalization())\n",
    "TModel.add(Dense(128,activation=\"sigmoid\"))\n",
    "TModel.add(Dense(28,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 3, 3, 2048)        58331648  \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 18432)             0         \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 18432)            73728     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 5000)              92165000  \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 5000)             20000     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 128)               640128    \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 28)                3612      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,234,116\n",
      "Trainable params: 92,855,604\n",
      "Non-trainable params: 58,378,512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "TModel.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3) ,metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 22:04:15.312926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.6091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 22:04:25.622602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 13s 80ms/step - loss: 0.0595 - accuracy: 0.6091 - val_loss: 1.1184 - val_accuracy: 0.7134\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0251 - accuracy: 0.8320 - val_loss: 0.8867 - val_accuracy: 0.7681\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0154 - accuracy: 0.9014 - val_loss: 0.7919 - val_accuracy: 0.7829\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0104 - accuracy: 0.9299 - val_loss: 0.7680 - val_accuracy: 0.7858\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0072 - accuracy: 0.9505 - val_loss: 0.6861 - val_accuracy: 0.8168\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0044 - accuracy: 0.9708 - val_loss: 0.6376 - val_accuracy: 0.8316\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0029 - accuracy: 0.9797 - val_loss: 0.6669 - val_accuracy: 0.8095\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0027 - accuracy: 0.9786 - val_loss: 0.6773 - val_accuracy: 0.8168\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0031 - accuracy: 0.9767 - val_loss: 0.7128 - val_accuracy: 0.8095\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 0.0020 - accuracy: 0.9849 - val_loss: 0.6954 - val_accuracy: 0.8124\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0022 - accuracy: 0.9808 - val_loss: 0.6561 - val_accuracy: 0.8213\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0015 - accuracy: 0.9893 - val_loss: 0.6617 - val_accuracy: 0.8227\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 0.0015 - accuracy: 0.9874 - val_loss: 0.6893 - val_accuracy: 0.8050\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 0.0013 - accuracy: 0.9915 - val_loss: 0.5800 - val_accuracy: 0.8360\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 9.0923e-04 - accuracy: 0.9934 - val_loss: 0.6186 - val_accuracy: 0.8287\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 7.7543e-04 - accuracy: 0.9937 - val_loss: 0.6266 - val_accuracy: 0.8257\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 4.8909e-04 - accuracy: 0.9959 - val_loss: 0.5727 - val_accuracy: 0.8493\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 7.1525e-04 - accuracy: 0.9959 - val_loss: 0.6540 - val_accuracy: 0.8316\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 7.9840e-04 - accuracy: 0.9937 - val_loss: 0.6266 - val_accuracy: 0.8272\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 8.8585e-04 - accuracy: 0.9948 - val_loss: 0.6752 - val_accuracy: 0.8168\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 0.0012 - accuracy: 0.9919 - val_loss: 0.6697 - val_accuracy: 0.8213\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 6.8508e-04 - accuracy: 0.9952 - val_loss: 0.6614 - val_accuracy: 0.8272\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 8.6043e-04 - accuracy: 0.9937 - val_loss: 0.6910 - val_accuracy: 0.8272\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 4.4740e-04 - accuracy: 0.9978 - val_loss: 0.6603 - val_accuracy: 0.8257\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 4.2676e-04 - accuracy: 0.9974 - val_loss: 0.6805 - val_accuracy: 0.8213\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 2.3877e-04 - accuracy: 0.9989 - val_loss: 0.6486 - val_accuracy: 0.8272\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 7.6499e-04 - accuracy: 0.9934 - val_loss: 0.6975 - val_accuracy: 0.8035\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 8.3206e-04 - accuracy: 0.9956 - val_loss: 0.6331 - val_accuracy: 0.8346\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 7.0445e-04 - accuracy: 0.9956 - val_loss: 0.8109 - val_accuracy: 0.7991\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 8.2690e-04 - accuracy: 0.9956 - val_loss: 0.7125 - val_accuracy: 0.8198\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 4.1382e-04 - accuracy: 0.9982 - val_loss: 0.8183 - val_accuracy: 0.8154\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 4.9728e-04 - accuracy: 0.9985 - val_loss: 0.7561 - val_accuracy: 0.8242\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 2.4679e-04 - accuracy: 0.9989 - val_loss: 0.6903 - val_accuracy: 0.8449\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 2.2686e-04 - accuracy: 0.9989 - val_loss: 0.7347 - val_accuracy: 0.8183\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 6.3106e-04 - accuracy: 0.9963 - val_loss: 0.7800 - val_accuracy: 0.8124\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 4.0840e-04 - accuracy: 0.9978 - val_loss: 0.8302 - val_accuracy: 0.7962\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 5.5098e-04 - accuracy: 0.9963 - val_loss: 0.7526 - val_accuracy: 0.8183\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 8.8056e-04 - accuracy: 0.9952 - val_loss: 0.7442 - val_accuracy: 0.8095\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 7.6462e-04 - accuracy: 0.9967 - val_loss: 0.7361 - val_accuracy: 0.8124\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 5s 57ms/step - loss: 5.9076e-04 - accuracy: 0.9959 - val_loss: 0.7000 - val_accuracy: 0.8213\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 6.2431e-04 - accuracy: 0.9959 - val_loss: 0.8082 - val_accuracy: 0.8065\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 8.8732e-04 - accuracy: 0.9948 - val_loss: 0.7983 - val_accuracy: 0.8168\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 8.4201e-04 - accuracy: 0.9967 - val_loss: 0.6672 - val_accuracy: 0.8227\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 3.9249e-04 - accuracy: 0.9982 - val_loss: 0.6920 - val_accuracy: 0.8331\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 4.8169e-04 - accuracy: 0.9967 - val_loss: 0.7141 - val_accuracy: 0.8346\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 6.5559e-04 - accuracy: 0.9974 - val_loss: 0.8180 - val_accuracy: 0.8168\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 5.5866e-04 - accuracy: 0.9959 - val_loss: 0.7165 - val_accuracy: 0.8242\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 2.5677e-04 - accuracy: 0.9989 - val_loss: 0.7079 - val_accuracy: 0.8331\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 1.2247e-04 - accuracy: 0.9996 - val_loss: 0.7247 - val_accuracy: 0.8183\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 5s 58ms/step - loss: 6.7008e-05 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "history = TModel.fit(train_generator, epochs=50,validation_data=valid_generator,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Test accuracy: 0.8282548189163208\n"
     ]
    }
   ],
   "source": [
    "score_Rmodel = TModel.evaluate(X_final_test,y_final_test, verbose = 0)\n",
    "\n",
    "#print('final Test loss:', score_cnn[0]) \n",
    "print('final Test accuracy:', score_Rmodel[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning using Xception model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcep_model=tf.keras.applications.Xception(include_top=False,weights=\"imagenet\",input_tensor=None,input_shape=(80, 80, 3))\n",
    "\n",
    "for l in Xcep_model.layers:\n",
    "# Freezing the model\n",
    "  l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "EModel = Sequential()\n",
    "EModel.add(Input(shape=(80,80,3)))\n",
    "EModel.add(Xcep_model)\n",
    "EModel.add(Flatten())\n",
    "EModel.add(BatchNormalization())\n",
    "EModel.add(Dense(5000,activation=\"relu\"))\n",
    "EModel.add(BatchNormalization())\n",
    "EModel.add(Dense(128,activation=\"sigmoid\"))\n",
    "EModel.add(Dense(28,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "EModel.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3) ,metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 22:08:32.930527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.5090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 22:08:38.023363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 6s 41ms/step - loss: 0.0703 - accuracy: 0.5090 - val_loss: 1.4364 - val_accuracy: 0.6366\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0375 - accuracy: 0.7442 - val_loss: 1.0792 - val_accuracy: 0.7194\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0269 - accuracy: 0.8165 - val_loss: 0.9434 - val_accuracy: 0.7489\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0189 - accuracy: 0.8693 - val_loss: 0.8247 - val_accuracy: 0.7740\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0150 - accuracy: 0.8937 - val_loss: 0.7889 - val_accuracy: 0.7888\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0133 - accuracy: 0.9077 - val_loss: 0.7807 - val_accuracy: 0.7725\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0109 - accuracy: 0.9162 - val_loss: 0.7327 - val_accuracy: 0.7991\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0090 - accuracy: 0.9343 - val_loss: 0.7533 - val_accuracy: 0.7903\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0067 - accuracy: 0.9520 - val_loss: 0.7238 - val_accuracy: 0.8035\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0056 - accuracy: 0.9594 - val_loss: 0.7672 - val_accuracy: 0.7976\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0058 - accuracy: 0.9535 - val_loss: 0.7565 - val_accuracy: 0.7873\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0058 - accuracy: 0.9520 - val_loss: 0.7490 - val_accuracy: 0.7858\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0054 - accuracy: 0.9579 - val_loss: 0.7740 - val_accuracy: 0.7932\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0044 - accuracy: 0.9627 - val_loss: 0.6946 - val_accuracy: 0.8065\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0039 - accuracy: 0.9671 - val_loss: 0.6421 - val_accuracy: 0.8272\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0035 - accuracy: 0.9705 - val_loss: 0.7844 - val_accuracy: 0.8080\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0042 - accuracy: 0.9675 - val_loss: 0.7848 - val_accuracy: 0.7799\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0031 - accuracy: 0.9738 - val_loss: 0.7113 - val_accuracy: 0.8139\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0032 - accuracy: 0.9756 - val_loss: 0.7329 - val_accuracy: 0.8006\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0028 - accuracy: 0.9764 - val_loss: 0.6964 - val_accuracy: 0.8154\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0032 - accuracy: 0.9738 - val_loss: 0.7421 - val_accuracy: 0.8080\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0028 - accuracy: 0.9782 - val_loss: 0.7543 - val_accuracy: 0.8006\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0026 - accuracy: 0.9797 - val_loss: 0.7311 - val_accuracy: 0.8050\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0025 - accuracy: 0.9779 - val_loss: 0.7427 - val_accuracy: 0.8065\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0024 - accuracy: 0.9793 - val_loss: 0.7199 - val_accuracy: 0.8065\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0024 - accuracy: 0.9815 - val_loss: 0.7335 - val_accuracy: 0.8021\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0026 - accuracy: 0.9764 - val_loss: 0.8156 - val_accuracy: 0.7858\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0026 - accuracy: 0.9786 - val_loss: 0.8393 - val_accuracy: 0.7917\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0027 - accuracy: 0.9804 - val_loss: 0.7734 - val_accuracy: 0.8050\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0024 - accuracy: 0.9808 - val_loss: 0.7925 - val_accuracy: 0.7888\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0030 - accuracy: 0.9764 - val_loss: 0.7604 - val_accuracy: 0.8035\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0022 - accuracy: 0.9841 - val_loss: 0.7700 - val_accuracy: 0.7947\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0025 - accuracy: 0.9793 - val_loss: 0.7086 - val_accuracy: 0.8124\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0033 - accuracy: 0.9716 - val_loss: 0.8089 - val_accuracy: 0.7947\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0034 - accuracy: 0.9697 - val_loss: 0.8023 - val_accuracy: 0.7932\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0030 - accuracy: 0.9771 - val_loss: 0.7468 - val_accuracy: 0.8095\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0020 - accuracy: 0.9838 - val_loss: 0.7647 - val_accuracy: 0.8006\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0021 - accuracy: 0.9834 - val_loss: 0.7484 - val_accuracy: 0.8257\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0021 - accuracy: 0.9830 - val_loss: 0.7949 - val_accuracy: 0.7932\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0024 - accuracy: 0.9808 - val_loss: 0.7386 - val_accuracy: 0.8109\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0017 - accuracy: 0.9878 - val_loss: 0.7389 - val_accuracy: 0.8154\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0018 - accuracy: 0.9878 - val_loss: 0.7763 - val_accuracy: 0.8168\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0015 - accuracy: 0.9886 - val_loss: 0.7450 - val_accuracy: 0.8257\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0015 - accuracy: 0.9882 - val_loss: 0.7841 - val_accuracy: 0.8139\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0014 - accuracy: 0.9904 - val_loss: 0.7057 - val_accuracy: 0.8183\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0013 - accuracy: 0.9886 - val_loss: 0.7947 - val_accuracy: 0.8109\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0012 - accuracy: 0.9922 - val_loss: 0.7393 - val_accuracy: 0.8095\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0013 - accuracy: 0.9904 - val_loss: 0.7964 - val_accuracy: 0.8183\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0017 - accuracy: 0.9863 - val_loss: 0.7836 - val_accuracy: 0.8154\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 3s 32ms/step - loss: 0.0019 - accuracy: 0.9849 - val_loss: 0.8357 - val_accuracy: 0.8035\n"
     ]
    }
   ],
   "source": [
    "history = EModel.fit(train_generator, epochs=50,validation_data=valid_generator,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Test accuracy: 0.8282548189163208\n"
     ]
    }
   ],
   "source": [
    "score_Emodel = EModel.evaluate(X_final_test,y_final_test, verbose = 0)\n",
    "\n",
    "#print('final Test loss:', score_cnn[0]) \n",
    "print('final Test accuracy:', score_Rmodel[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above models considering the best model based on the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model=Model## This is the simple CNN model without any transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the best model for precision,recall,f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = Model.predict(X_final_test)\n",
    "y_final_test=np.argmax(y_final_test, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "test_acc=accuracy_score(y_pred_labels,y_final_test)\n",
    "test_prec=precision_score(y_pred_labels,y_final_test,average='weighted')\n",
    "test_recall=recall_score(y_pred_labels,y_final_test,average='weighted')\n",
    "test_f1=f1_score(y_pred_labels,y_final_test,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table={\"data\":[\"Testing_data\"],\"Accuracy\":[round(test_acc,2)],\"Precision\":[round(test_prec,2)],\"Recall\":[round(test_recall,2)],\"F1 Score\":[round(test_f1,2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table=pd.DataFrame(Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Testing_data</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           data  Accuracy  Precision  Recall  F1 Score\n",
       "0  Testing_data      0.94       0.94    0.94      0.94"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table.to_csv(\"Results_on_Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_model.save(\"Best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python script to run the CNN model using OpenCV's dnn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To run the below code we need a saved tensorflow cnn model\n",
    "\n",
    "Opcv_model = cv2.dnn.readNetFromTensorflow(\"path_to_model_graph\",\"path_to_model_architecture\")\n",
    "\n",
    "random_img=cv2.imread(\"image_path\")\n",
    "\n",
    "random_img=random_img/255.0  #for normalizing the image\n",
    "\n",
    "random_img=cv2.resize(img,(80,80))  # resizing the image\n",
    "\n",
    "random_img=random_img[None,:]  # Extending the dimension as the model take input with size (batch,height,width,channel)\n",
    "\n",
    "Opcv_model.setInput(random_img)\n",
    "\n",
    "output = net.forward()\n",
    "\n",
    "output_label = np.argmax(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
